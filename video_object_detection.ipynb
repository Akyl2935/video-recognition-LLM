{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Video Object Detection using YOLO\n",
        "\n",
        "This notebook demonstrates object detection in video files using YOLO (You Only Look Once) and evaluates the results using Intersection over Union (IOU).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Setup and Imports\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import json\n",
        "import os\n",
        "from pathlib import Path\n",
        "from typing import List, Tuple, Dict\n",
        "from ultralytics import YOLO\n",
        "import matplotlib.pyplot as plt\n",
        "from collections import defaultdict\n",
        "\n",
        "print(\"Libraries imported successfully!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Configuration\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Configuration\n",
        "INPUT_VIDEO = \"input_video.mp4\"  # Change this to your video file path\n",
        "OUTPUT_VIDEO = \"output_video.mp4\"  # Output video with bounding boxes\n",
        "MODEL_NAME = \"yolov8n.pt\"  # YOLO model (yolov8n.pt, yolov8s.pt, yolov8m.pt, etc.)\n",
        "CONFIDENCE_THRESHOLD = 0.25  # Minimum confidence for detections\n",
        "DETECTION_CLASS = 0  # 0 = person in COCO dataset\n",
        "GROUND_TRUTH_FILE = \"ground_truth.json\"  # Ground truth annotations (if available)\n",
        "IOU_THRESHOLD = 0.5  # IOU threshold for matching detections to ground truth\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Helper Functions\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def calculate_iou(boxA: List[float], boxB: List[float]) -> float:\n",
        "    \"\"\"\n",
        "    Calculate Intersection over Union (IOU) between two bounding boxes.\n",
        "    \n",
        "    Args:\n",
        "        boxA: Bounding box [x1, y1, x2, y2]\n",
        "        boxB: Bounding box [x1, y1, x2, y2]\n",
        "        \n",
        "    Returns:\n",
        "        IOU value between 0 and 1\n",
        "    \"\"\"\n",
        "    # Determine coordinates of intersection rectangle\n",
        "    xA = max(boxA[0], boxB[0])\n",
        "    yA = max(boxA[1], boxB[1])\n",
        "    xB = min(boxA[2], boxB[2])\n",
        "    yB = min(boxA[3], boxB[3])\n",
        "    \n",
        "    # Compute area of intersection\n",
        "    inter_area = max(0, xB - xA) * max(0, yB - yA)\n",
        "    \n",
        "    # Compute area of both bounding boxes\n",
        "    boxA_area = (boxA[2] - boxA[0]) * (boxA[3] - boxA[1])\n",
        "    boxB_area = (boxB[2] - boxB[0]) * (boxB[3] - boxB[1])\n",
        "    \n",
        "    # Compute IOU\n",
        "    union_area = boxA_area + boxB_area - inter_area\n",
        "    if union_area == 0:\n",
        "        return 0.0\n",
        "    \n",
        "    iou = inter_area / union_area\n",
        "    return iou\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Load YOLO Model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load YOLO model\n",
        "print(f\"Loading YOLO model: {MODEL_NAME}\")\n",
        "model = YOLO(MODEL_NAME)\n",
        "print(\"Model loaded successfully!\")\n",
        "\n",
        "# Display model info\n",
        "print(f\"\\nModel classes: {len(model.names)} classes\")\n",
        "print(f\"Class 0 (person): {model.names[0]}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Process Video and Detect Objects\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Open video file\n",
        "cap = cv2.VideoCapture(INPUT_VIDEO)\n",
        "\n",
        "if not cap.isOpened():\n",
        "    raise ValueError(f\"Could not open video file: {INPUT_VIDEO}\")\n",
        "\n",
        "# Get video properties\n",
        "frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
        "total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "\n",
        "print(f\"Video properties:\")\n",
        "print(f\"  Resolution: {frame_width}x{frame_height}\")\n",
        "print(f\"  FPS: {fps}\")\n",
        "print(f\"  Total frames: {total_frames}\")\n",
        "print(f\"  Duration: {total_frames/fps:.2f} seconds\")\n",
        "\n",
        "# Define codec and create VideoWriter\n",
        "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
        "out = cv2.VideoWriter(OUTPUT_VIDEO, fourcc, fps, (frame_width, frame_height))\n",
        "\n",
        "# Storage for detections\n",
        "all_detections = {}\n",
        "frame_count = 0\n",
        "total_detections = 0\n",
        "\n",
        "print(f\"\\nProcessing video...\")\n",
        "\n",
        "while cap.isOpened():\n",
        "    ret, frame = cap.read()\n",
        "    if not ret:\n",
        "        break\n",
        "    \n",
        "    # Detect objects\n",
        "    results = model(frame, conf=CONFIDENCE_THRESHOLD, verbose=False)\n",
        "    \n",
        "    frame_detections = []\n",
        "    annotated_frame = frame.copy()\n",
        "    \n",
        "    for result in results:\n",
        "        boxes = result.boxes\n",
        "        for i in range(len(boxes)):\n",
        "            box = boxes.xyxy[i].cpu().numpy()  # [x1, y1, x2, y2]\n",
        "            confidence = float(boxes.conf[i].cpu().numpy())\n",
        "            class_id = int(boxes.cls[i].cpu().numpy())\n",
        "            \n",
        "            # Filter by class (0 = person)\n",
        "            if class_id == DETECTION_CLASS:\n",
        "                x1, y1, x2, y2 = map(int, box)\n",
        "                \n",
        "                # Draw bounding box\n",
        "                cv2.rectangle(annotated_frame, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
        "                \n",
        "                # Draw label with confidence\n",
        "                label = f\"Person {confidence:.2f}\"\n",
        "                label_size, _ = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 0.5, 2)\n",
        "                cv2.rectangle(annotated_frame, (x1, y1 - label_size[1] - 10), \n",
        "                            (x1 + label_size[0], y1), (0, 255, 0), -1)\n",
        "                cv2.putText(annotated_frame, label, (x1, y1 - 5), \n",
        "                           cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 0), 2)\n",
        "                \n",
        "                frame_detections.append({\n",
        "                    'bbox': box.tolist(),\n",
        "                    'confidence': confidence,\n",
        "                    'class_id': class_id\n",
        "                })\n",
        "    \n",
        "    # Save detections for this frame\n",
        "    all_detections[frame_count] = frame_detections\n",
        "    total_detections += len(frame_detections)\n",
        "    \n",
        "    # Write frame to output video\n",
        "    out.write(annotated_frame)\n",
        "    \n",
        "    frame_count += 1\n",
        "    if frame_count % 30 == 0:\n",
        "        print(f\"Processed {frame_count}/{total_frames} frames...\")\n",
        "\n",
        "cap.release()\n",
        "out.release()\n",
        "\n",
        "print(f\"\\nProcessing complete!\")\n",
        "print(f\"Total frames processed: {frame_count}\")\n",
        "print(f\"Total detections: {total_detections}\")\n",
        "print(f\"Average detections per frame: {total_detections/frame_count:.2f}\")\n",
        "print(f\"Output video saved to: {OUTPUT_VIDEO}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Save Detections\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Save detections to JSON\n",
        "detections_path = OUTPUT_VIDEO.replace('.mp4', '_detections.json')\n",
        "with open(detections_path, 'w') as f:\n",
        "    json.dump(all_detections, f, indent=2)\n",
        "\n",
        "print(f\"Detections saved to: {detections_path}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Evaluate with Ground Truth (if available)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def match_detections_to_ground_truth(detections: List[Dict], \n",
        "                                     ground_truth: List[List[float]], \n",
        "                                     iou_threshold: float = 0.5) -> Tuple[List[float], List[bool]]:\n",
        "    \"\"\"Match detected bounding boxes to ground truth boxes using IOU.\"\"\"\n",
        "    if not detections or not ground_truth:\n",
        "        return [], [False] * len(detections)\n",
        "    \n",
        "    matched_ious = []\n",
        "    match_flags = [False] * len(detections)\n",
        "    used_gt = [False] * len(ground_truth)\n",
        "    \n",
        "    # Calculate IOU for all pairs\n",
        "    iou_matrix = []\n",
        "    for det in detections:\n",
        "        det_bbox = det['bbox']\n",
        "        ious = []\n",
        "        for gt_bbox in ground_truth:\n",
        "            iou = calculate_iou(det_bbox, gt_bbox)\n",
        "            ious.append(iou)\n",
        "        iou_matrix.append(ious)\n",
        "    \n",
        "    # Greedy matching: match highest IOU pairs first\n",
        "    while True:\n",
        "        max_iou = 0\n",
        "        best_det_idx = -1\n",
        "        best_gt_idx = -1\n",
        "        \n",
        "        for det_idx, ious in enumerate(iou_matrix):\n",
        "            if match_flags[det_idx]:\n",
        "                continue\n",
        "            for gt_idx, iou in enumerate(ious):\n",
        "                if used_gt[gt_idx]:\n",
        "                    continue\n",
        "                if iou > max_iou:\n",
        "                    max_iou = iou\n",
        "                    best_det_idx = det_idx\n",
        "                    best_gt_idx = gt_idx\n",
        "        \n",
        "        if max_iou >= iou_threshold and best_det_idx >= 0:\n",
        "            matched_ious.append(max_iou)\n",
        "            match_flags[best_det_idx] = True\n",
        "            used_gt[best_gt_idx] = True\n",
        "        else:\n",
        "            break\n",
        "    \n",
        "    return matched_ious, match_flags\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load ground truth if available\n",
        "if os.path.exists(GROUND_TRUTH_FILE):\n",
        "    print(f\"Loading ground truth from: {GROUND_TRUTH_FILE}\")\n",
        "    with open(GROUND_TRUTH_FILE, 'r') as f:\n",
        "        ground_truth = json.load(f)\n",
        "    \n",
        "    # Evaluate detections\n",
        "    all_ious = []\n",
        "    frame_metrics = {}\n",
        "    \n",
        "    for frame_num_str, frame_detections in all_detections.items():\n",
        "        frame_num = int(frame_num_str)\n",
        "        \n",
        "        if str(frame_num) not in ground_truth:\n",
        "            continue\n",
        "        \n",
        "        gt_boxes = ground_truth[str(frame_num)]\n",
        "        matched_ious, match_flags = match_detections_to_ground_truth(\n",
        "            frame_detections, gt_boxes, IOU_THRESHOLD\n",
        "        )\n",
        "        \n",
        "        all_ious.extend(matched_ious)\n",
        "        \n",
        "        # Calculate metrics for this frame\n",
        "        true_positives = len(matched_ious)\n",
        "        false_positives = sum(1 for flag in match_flags if not flag)\n",
        "        false_negatives = len(gt_boxes) - true_positives\n",
        "        \n",
        "        precision = true_positives / (true_positives + false_positives) if (true_positives + false_positives) > 0 else 0\n",
        "        recall = true_positives / (true_positives + false_negatives) if (true_positives + false_negatives) > 0 else 0\n",
        "        f1_score = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
        "        \n",
        "        frame_metrics[frame_num] = {\n",
        "            'true_positives': true_positives,\n",
        "            'false_positives': false_positives,\n",
        "            'false_negatives': false_negatives,\n",
        "            'precision': precision,\n",
        "            'recall': recall,\n",
        "            'f1_score': f1_score,\n",
        "            'avg_iou': np.mean(matched_ious) if matched_ious else 0,\n",
        "            'matched_ious': matched_ious\n",
        "        }\n",
        "    \n",
        "    # Overall metrics\n",
        "    mean_iou = np.mean(all_ious) if all_ious else 0\n",
        "    median_iou = np.median(all_ious) if all_ious else 0\n",
        "    \n",
        "    print(f\"\\n{'='*80}\")\n",
        "    print(f\"EVALUATION RESULTS\")\n",
        "    print(f\"{'='*80}\")\n",
        "    print(f\"Mean IOU: {mean_iou:.4f}\")\n",
        "    print(f\"Median IOU: {median_iou:.4f}\")\n",
        "    print(f\"Total Matches: {len(all_ious)}\")\n",
        "    print(f\"\\nPer-frame metrics:\")\n",
        "    for frame_num, metrics in sorted(frame_metrics.items()):\n",
        "        print(f\"\\nFrame {frame_num}:\")\n",
        "        print(f\"  Precision: {metrics['precision']:.4f}\")\n",
        "        print(f\"  Recall: {metrics['recall']:.4f}\")\n",
        "        print(f\"  F1 Score: {metrics['f1_score']:.4f}\")\n",
        "        print(f\"  Average IOU: {metrics['avg_iou']:.4f}\")\n",
        "        \n",
        "    # Visualize IOU distribution\n",
        "    if all_ious:\n",
        "        plt.figure(figsize=(10, 6))\n",
        "        plt.hist(all_ious, bins=20, edgecolor='black')\n",
        "        plt.xlabel('IOU Value')\n",
        "        plt.ylabel('Frequency')\n",
        "        plt.title('Distribution of IOU Values')\n",
        "        plt.axvline(mean_iou, color='r', linestyle='--', label=f'Mean IOU: {mean_iou:.3f}')\n",
        "        plt.legend()\n",
        "        plt.grid(True, alpha=0.3)\n",
        "        plt.show()\n",
        "else:\n",
        "    print(f\"Ground truth file not found: {GROUND_TRUTH_FILE}\")\n",
        "    print(\"To create ground truth annotations, use the annotate_ground_truth.py script\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Display a few sample frames from the output video\n",
        "cap = cv2.VideoCapture(OUTPUT_VIDEO)\n",
        "sample_frames = [0, total_frames // 4, total_frames // 2, 3 * total_frames // 4]\n",
        "\n",
        "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
        "axes = axes.flatten()\n",
        "\n",
        "for idx, frame_num in enumerate(sample_frames):\n",
        "    cap.set(cv2.CAP_PROP_POS_FRAMES, frame_num)\n",
        "    ret, frame = cap.read()\n",
        "    \n",
        "    if ret:\n",
        "        # Convert BGR to RGB for matplotlib\n",
        "        frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
        "        axes[idx].imshow(frame_rgb)\n",
        "        axes[idx].set_title(f\"Frame {frame_num}\")\n",
        "        axes[idx].axis('off')\n",
        "\n",
        "cap.release()\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
